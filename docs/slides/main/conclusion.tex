\begin{tframe}{Conclusion}

The results show that for the clean samples the classification for the mixed and adversarial model behaved as for the standard model. 

\vspace{0.1in}

For the adversarial examples, however, the results are much better than the standard approach. For both the mixed and adversarial model, the error rate dropped of $\sim 80\%$ and the confidence for the misclassification also dropped significantly, settling in a similar range as the clean samples for every model.

\vspace{0.1in}

The results shows that the new models performed well even with adversarial examples generated by other models. Also, consistent with the results of [1], the error rate and the error confidence for the standard model dropped when using adversarial examples generated by the mixed or the adversarial models.

\end{tframe}